# Hegelion Configuration
#
# Copy this file to .env and fill in the required values.
# See the README and docs/USER_GUIDE.md for more details.

# -------------------------
# --- Provider Settings ---
# -------------------------
# The primary LLM provider to use.
# Supported: "anthropic", "openai", "google", "ollama", "custom_http", "auto"
# Default: "auto" (tries providers in order: anthropic, openai, google)
HEGELION_PROVIDER="auto"

# The specific model to use for dialectical reasoning.
# Make sure this model is compatible with your chosen provider.
# Example for Anthropic: "claude-3-opus-20240229"
# Example for OpenAI: "gpt-4-turbo"
# Example for Google: "gemini-1.5-pro-latest"
# Example for Ollama: "llama3"
HEGELION_MODEL="claude-3-opus-20240229"

# --------------------
# --- API Keys ---
# --------------------
# Provide the API key for the service you intend to use.
# You only need to fill in the key for your chosen HEGELION_PROVIDER.

ANTHROPIC_API_KEY="sk-ant-..."
OPENAI_API_KEY="sk-..."
GOOGLE_API_KEY="AIzaSy..."
# CUSTOM_API_KEY is used if HEGELION_PROVIDER="custom_http"
CUSTOM_API_KEY=""

# ---------------------------
# --- Backend Endpoints ---
# ---------------------------
# These are optional and should only be changed if you are using a proxy,
# a self-hosted model, or a non-standard API endpoint.

# For HEGELION_PROVIDER="ollama"
OLLAMA_BASE_URL="http://localhost:11434"

# For HEGELION_PROVIDER="custom_http"
CUSTOM_API_BASE_URL=""

# For OpenAI-compatible endpoints (e.g., self-hosted)
# OPENAI_BASE_URL="http://localhost:8000/v1"

# ---------------------------
# --- Engine Tuning ---
# ---------------------------
# Advanced settings to control the dialectical process.
# It's recommended to use the defaults unless you have a specific need.

# Minimum score for a synthesis to be considered successful (0.0 to 1.0).
# HEGELION_SYNTHESIS_THRESHOLD="0.85"

# Maximum number of tokens to generate for each phase (thesis, antithesis, synthesis).
# HEGELION_MAX_TOKENS_PER_PHASE="8000"